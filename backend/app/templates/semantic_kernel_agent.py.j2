"""{{ project_name }} â€” {{ template_name }}

{{ template_description }}

Generated by +12 Monkeys â€¢ Framework: Semantic Kernel
"""

import asyncio
import os
from dotenv import load_dotenv

import semantic_kernel as sk
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.connectors.ai.anthropic import AnthropicChatCompletion
from semantic_kernel.functions import kernel_function

load_dotenv()

# ---------------------------------------------------------------------------
# Kernel Setup
# ---------------------------------------------------------------------------
kernel = sk.Kernel()

# Add Anthropic chat service
kernel.add_service(
    AnthropicChatCompletion(
        ai_model_id=os.getenv("LLM_MODEL", "claude-sonnet-4-20250514"),
        api_key=os.getenv("ANTHROPIC_API_KEY"),
        service_id="anthropic",
    )
)

{% for agent in agents %}
# ---------------------------------------------------------------------------
# Plugin: {{ agent.role }}
# ---------------------------------------------------------------------------
class {{ agent.role | capitalize }}Plugin:
    """{{ agent.goal }}"""

    @kernel_function(
        name="{{ agent.role }}_execute",
        description="{{ agent.goal }}",
    )
    def execute(self, input: str) -> str:
        """Run the {{ agent.role }} function."""
        return input

{% endfor %}

# Register plugins
{% for agent in agents %}
kernel.add_plugin({{ agent.role | capitalize }}Plugin(), plugin_name="{{ agent.role }}")
{% endfor %}


# ---------------------------------------------------------------------------
# Pipeline
# ---------------------------------------------------------------------------
async def run_pipeline(user_input: str) -> str:
    """Execute the agent pipeline sequentially."""
    settings = kernel.get_prompt_execution_settings_from_service_id("anthropic")
    settings.max_tokens = 4096

    current_input = user_input
    results = {}

    {% for agent in agents %}
    # Step {{ loop.index }}: {{ agent.role }}
    prompt_{{ loop.index }} = (
        "You are the {{ agent.role }} agent. Your goal: {{ agent.goal }}\n\n"
        f"Input: {current_input}\n"
        {% if not loop.first %}
        f"Previous context: {results.get('step_{{ loop.index0 }}', '')}\n"
        {% endif %}
        "Provide your output:"
    )
    response_{{ loop.index }} = await kernel.invoke_prompt(
        prompt_{{ loop.index }},
        settings=settings,
    )
    results["step_{{ loop.index }}"] = str(response_{{ loop.index }})
    current_input = results["step_{{ loop.index }}"]
    print(f"  âœ… {{ agent.role }} complete")

    {% endfor %}
    return current_input


# ---------------------------------------------------------------------------
# Entry Point
# ---------------------------------------------------------------------------
def main():
    import sys
    user_input = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else "Hello, I need help."
    print(f"\nðŸš€ Starting {{ project_name }} pipeline...\n")
    result = asyncio.run(run_pipeline(user_input))
    print(f"\nâœ… Result:\n{result}")


if __name__ == "__main__":
    main()

